#!/usr/bin/env python3
"""
TDD MBPP Pipeline
Two-stage pipeline: test generation -> implementation generation
"""

import os
import sys
import datetime
import json
from tqdm import tqdm
sys.path.append('.')

from pipelines.batch_base import BaseBatchPipeline
from pipelines.lc_chain.generator import (
    generate_tests_for_mbpp, 
    generate_implementation_with_tests_mbpp
)

class TDDMBPPBatchPipeline(BaseBatchPipeline):
    """TDDç‰ˆæœ¬çš„MBPPæ‰¹å¤„ç†ç®¡é“"""
    
    def read_problems(self, problem_file):
        """å¤ç”¨MBPPçš„é—®é¢˜è¯»å–é€»è¾‘"""
        problems = {}
        with open(problem_file, 'r') as f:
            for line in f:
                problem = json.loads(line.strip())
                problems[problem['task_id']] = problem
        return problems
    
    def get_output_filename(self, num_tasks, prefix):
        """ç”ŸæˆTDDç‰ˆæœ¬çš„è¾“å‡ºæ–‡ä»¶å"""
        return f"benchmarks/mbpp/data/{prefix}_{num_tasks}_tasks_{self.model}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
    
    def create_sample(self, task_id, problem, completion, error=None, generated_tests=None):
        """åˆ›å»ºTDDç‰ˆæœ¬çš„æ ·æœ¬"""
        sample = {
            "task_id": task_id,
            "prompt": problem['text'],
            "completion": completion,
            "method": "tdd_mbpp",  # æ ‡è¯†è¿™æ˜¯TDDæ–¹æ³•
            "model": self.model,
            "timestamp": datetime.datetime.now().isoformat(),
            "test_list": problem.get('test_list', []),
            "challenge_test_list": problem.get('challenge_test_list', []),
            "reference_code": problem.get('code', ''),
            "generated_tests": generated_tests,  # æ–°å¢ï¼šç”Ÿæˆçš„æµ‹è¯•
            "tdd_stage": "implementation"  # æ ‡è¯†è¿™æ˜¯å®ç°é˜¶æ®µçš„ç»“æœ
        }
        if error:
            sample["error"] = error
        return sample
    
    def save_results(self, output_file, samples):
        """å¤ç”¨MBPPçš„ä¿å­˜é€»è¾‘"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w') as f:
            for sample in samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    def get_prompt(self, problem):
        """TDDæµç¨‹ä¸éœ€è¦ä¼ ç»Ÿpromptï¼Œè¿”å›é—®é¢˜æè¿°"""
        return problem['text']
    
    def run_batch_pipeline(self, problem_file, num_tasks=10, start_task=0):
        """é‡å†™æ‰¹å¤„ç†é€»è¾‘ï¼Œå®ç°ä¸¤é˜¶æ®µTDDæµç¨‹"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_file = self.generate_batch_output_filename(num_tasks, "tdd_mbpp_batch")
            
            # è¯»å–é—®é¢˜
            print(f"Reading MBPP problem file: {problem_file}")
            problems = self.read_problems(problem_file)
            print(f"Total MBPP problems available: {len(problems)}")
            
            # ä½¿ç”¨æ‰€æœ‰å¯ç”¨ä»»åŠ¡ï¼ˆä¸è¿‡æ»¤å®˜æ–¹æµ‹è¯•é›†ï¼‰
            task_ids = list(problems.keys())
            task_ids.sort(key=int)
            
            end_task = min(start_task + num_tasks, len(task_ids))
            selected_task_ids = task_ids[start_task:end_task]
            
            print(f"Processing TDD MBPP tasks {selected_task_ids[0]} to {selected_task_ids[-1]} ({len(selected_task_ids)} tasks)")
            print(f"Using model: {self.model}")
            print("=" * 50)
            
            # ä¸¤é˜¶æ®µå¤„ç†
            samples = []
            for task_id in tqdm(selected_task_ids, desc="TDD Pipeline"):
                problem = problems[task_id]
                try:
                    description = problem['text']
                    
                    # é˜¶æ®µ1ï¼šç”Ÿæˆæµ‹è¯•
                    print(f"\nğŸ”„ Stage 1: Generating tests for task {task_id}")
                    reference_code = problem.get('code', '')  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå 'code'
                    generated_tests = generate_tests_for_mbpp(description, reference_code, self.model)
                    print(f"âœ… Tests generated: {len(generated_tests)} characters")
                    
                    # é˜¶æ®µ2ï¼šæ ¹æ®æµ‹è¯•ç”Ÿæˆå®ç°
                    print(f"ğŸ”„ Stage 2: Generating implementation for task {task_id}")
                    implementation = generate_implementation_with_tests_mbpp(
                        description, generated_tests, reference_code, self.model
                    )
                    print(f"âœ… Implementation generated: {len(implementation)} characters")
                    
                    # åˆ›å»ºæ ·æœ¬
                    sample = self.create_sample(task_id, problem, implementation, generated_tests=generated_tests)
                    samples.append(sample)
                    
                except Exception as e:
                    print(f"Error processing {task_id}: {e}")
                    sample = self.create_sample(task_id, problem, "    pass", error=str(e))
                    samples.append(sample)
            
            # ä¿å­˜ç»“æœ
            self.save_results(output_file, samples)
               
            print(f"\nResults saved: {output_file}")
            
            # æ‰“å°æ‘˜è¦
            successful = sum(1 for s in samples if 'error' not in s)
            failed = len(samples) - successful
            print(f"Summary: {successful} successful, {failed} failed")
            
            return output_file
            
        except Exception as e:
            print(f"TDD batch processing failed: {e}")
            return None

def run_tdd_mbpp_pipeline(problem_file="benchmarks/mbpp/mbpp/mbpp.jsonl", 
                         num_tasks=10, 
                         model="gpt-4o-mini",
                         start_task=0):
    """è¿è¡ŒTDD MBPPç®¡é“"""
    pipeline = TDDMBPPBatchPipeline(model)
    return pipeline.run_batch_pipeline(problem_file, num_tasks, start_task)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="TDD MBPP Pipeline")
    parser.add_argument("--num_tasks", type=int, default=10, help="Number of tasks to process")
    parser.add_argument("--model", type=str, default="gpt-4o-mini", help="Model to use")
    parser.add_argument("--start_task", type=int, default=0, help="Starting task index")
    parser.add_argument("--problem_file", type=str, default="benchmarks/mbpp/mbpp/mbpp.jsonl", 
                       help="MBPP problem file path")
    
    args = parser.parse_args()
    
    print("Starting TDD MBPP Pipeline")
    print("=" * 50)
    
    output_file = run_tdd_mbpp_pipeline(
        problem_file=args.problem_file,
        num_tasks=args.num_tasks,
        model=args.model,
        start_task=args.start_task
    )
    
    if output_file:
        print("\nTDD pipeline completed successfully!")
        print(f"Result file: {output_file}")
        print("\nNext steps:")
        print(f"1. Run evaluation: analyze_mbpp_results_fixed.py {output_file}")
        print(f"2. View results: cat {output_file}")
    else:
        print("\nTDD pipeline failed")
        sys.exit(1)

if __name__ == "__main__":
    main()
